# Ethiopian Child Microbiome Analysis - 16S Pipeline

## Part 1: QIIME2 Analysis Pipeline

### 1.1 Initial Setup and Data Import

```{bash}
# Set working directory - UPDATE THIS PATH FOR YOUR SYSTEM
cd /path/to/your/analysis

# Create output directories
mkdir -p qiime_output
mkdir -p results
mkdir -p metadata

# Activate QIIME2 environment
conda activate qiime2-amplicon-2025.7
```

### 1.2 Create Sample Manifest File

```{bash}
# Generate manifest file for QIIME2 import
python3 << 'EOF'
import os
import pandas as pd

# Base path to clean sequencing data - UPDATE THIS PATH FOR YOUR SYSTEM
base_path = "/path/to/your/CleanData"

# Identify all sample directories and corresponding fastq files
samples = []
for item in os.listdir(base_path):
    sample_dir = os.path.join(base_path, item)
    if os.path.isdir(sample_dir):
        fq_file = os.path.join(sample_dir, f"{item}.extendedFrags.fastq.gz")
        if os.path.exists(fq_file):
            samples.append({
                'sample-id': item,
                'absolute-filepath': fq_file,
                'direction': 'forward'
            })

# Create and save manifest DataFrame
manifest_df = pd.DataFrame(samples)
manifest_df.to_csv('metadata/manifest.tsv', sep='\t', index=False)
print(f"Created manifest with {len(samples)} samples")
print(manifest_df.head())
EOF
```

### 1.3 Import Sequences

```{bash}
# Import sequences using manifest
qiime tools import \
  --type 'SampleData[SequencesWithQuality]' \
  --input-path metadata/manifest_renamed.tsv \
  --input-format SingleEndFastqManifestPhred33V2 \
  --output-path qiime_output/demux-single-end.qza

# Generate demultiplexing summary for quality assessment
qiime demux summarize \
  --i-data qiime_output/demux-single-end.qza \
  --o-visualization qiime_output/demux-single-end.qzv
```

### 1.4 Quality Control and Denoising with DADA2

```{bash}
# DADA2 denoising to generate ASV table
# Parameters: trim 5bp from left, no truncation
qiime dada2 denoise-single \
  --i-demultiplexed-seqs qiime_output/demux-single-end.qza \
  --p-trim-left 5 \
  --p-trunc-len 0 \
  --o-table qiime_output/table-dada2.qza \
  --o-representative-sequences qiime_output/rep-seqs-dada2.qza \
  --o-denoising-stats qiime_output/denoising-stats-dada2.qza \
  --p-n-threads 11

# Generate feature table summary
qiime feature-table summarize \
  --i-table qiime_output/table-dada2.qza \
  --o-visualization qiime_output/table-dada2.qzv

# Generate representative sequences summary
qiime feature-table tabulate-seqs \
  --i-data qiime_output/rep-seqs-dada2.qza \
  --o-visualization qiime_output/rep-seqs-dada2.qzv
```

### 1.5 Taxonomic Classification with Multiple Classifiers

```{bash}
# Define classifier names and file paths - UPDATE PATHS FOR YOUR SYSTEM
declare -A CLASSIFIERS=(
  ["greengenes2"]="/path/to/classifiers/2024.09.backbone.full-length.nb.sklearn-1.4.2.qza"
  ["silva138_stool"]="/path/to/classifiers/silva-138-99-nb-human-stool-weighted-classifier.qza"
  ["silva138_normal"]="/path/to/classifiers/silva-138-99-nb-classifier.qza"
  ["gtdb"]="/path/to/classifiers/gtdb_human_stool_weighted_classifier_r220.qza"
)

# Create taxonomy output directories
mkdir -p qiime_output/taxonomy_comparisons_deblur
mkdir -p qiime_output/taxonomy_comparisons_dada2

# Run classification with each classifier
for classifier_name in "${!CLASSIFIERS[@]}"; do
  classifier_file="${CLASSIFIERS[$classifier_name]}"

  echo "Running classification with ${classifier_name}..."

  # Verify classifier file exists
  if [[ ! -f "$classifier_file" ]]; then
    echo "Warning: Classifier file not found: $classifier_file"
    continue
  fi

  # Run sklearn-based classification
  qiime feature-classifier classify-sklearn \
    --i-classifier "$classifier_file" \
    --p-n-jobs 11 \
    --i-reads qiime_output/rep-seqs-dada2.qza \
    --o-classification qiime_output/taxonomy_comparisons_dada2/taxonomy_${classifier_name}.qza \
    --verbose

  # Generate taxonomy barplot visualisation
  qiime taxa barplot \
    --i-table qiime_output/table-dada2.qza \
    --i-taxonomy qiime_output/taxonomy_comparisons_dada2/taxonomy_${classifier_name}.qza \
    --o-visualization qiime_output/taxonomy_comparisons_dada2/taxa-bar-plots_${classifier_name}.qzv

  # Export taxonomy for downstream R analysis
  qiime tools export \
    --input-path qiime_output/taxonomy_comparisons_dada2/taxonomy_${classifier_name}.qza \
    --output-path qiime_output/taxonomy_comparisons_dada2/exported_${classifier_name}

  echo "Completed classification with ${classifier_name}"
done
```

### 1.6 Phylogenetic Tree Construction

```{bash}
# Multiple sequence alignment using MAFFT
qiime alignment mafft \
  --i-sequences qiime_output/rep-seqs-dada2.qza \
  --o-alignment qiime_output/aligned-rep-seqs-dada2.qza \
  --p-n-threads 16

# Mask highly variable positions in alignment
qiime alignment mask \
  --i-alignment qiime_output/aligned-rep-seqs-dada2.qza \
  --o-masked-alignment qiime_output/masked-aligned-rep-seqs-dada2.qza

# Generate phylogenetic tree using FastTree
qiime phylogeny fasttree \
  --i-alignment qiime_output/masked-aligned-rep-seqs-dada2.qza \
  --o-tree qiime_output/unrooted-tree-dada2.qza \
  --p-n-threads 11

# Root the tree at midpoint
qiime phylogeny midpoint-root \
  --i-tree qiime_output/unrooted-tree-dada2.qza \
  --o-rooted-tree qiime_output/rooted-tree-dada2.qza
```

### 1.7 Diversity Analysis

```{bash}
# Calculate core diversity metrics (alpha and beta diversity)
# Sampling depth of 24,000 reads determined from rarefaction curves
qiime diversity core-metrics-phylogenetic \
  --i-phylogeny qiime_output/rooted-tree-dada2.qza \
  --i-table qiime_output/table-dada2-filtered.qza \
  --p-sampling-depth 24000 \
  --p-n-jobs-or-threads 16 \
  --output-dir qiime_output/core-metrics-results-dada2 \
  --m-metadata-file metadata/sample_metadata.txt
```

---

## Part 2: R Analysis Pipeline

### 2.1 Setup R Environment and Define Paths

```{r setup, message=FALSE, warning=FALSE}
# Load required libraries
library(qiime2R)
library(tidyverse)
library(ggprism)
library(vegan)
library(phyloseq)
library(ape)
library(ggpubr)
library(rstatix)
library(kableExtra)
library(parallel)
library(matrixStats)
library(ComplexHeatmap)
library(DESeq2)
library(ggrepel)
library(DT)
library(ggbeeswarm)
library(circlize)
library(viridis)
library(RColorBrewer)
library(readxl)
library(dplyr)

# ========== UPDATE THESE PATHS FOR YOUR SYSTEM ==========
# Define base directories for input/output files
base_dir <- "/path/to/your/analysis"
qiime_output_dir <- file.path(base_dir, "qiime_output")
results_dir <- file.path(base_dir, "results")
data_dir <- file.path(base_dir, "data")
metadata_file <- file.path(base_dir, "metadata/sample_metadata.xlsx")
# =========================================================

# Create results directory if it doesn't exist
if (!dir.exists(results_dir)) dir.create(results_dir, recursive = TRUE)
```

### 2.2 Load and Prepare Data

```{r load_data, message=FALSE, warning=FALSE}
# Load metadata
metadata <- read_xlsx(metadata_file, sheet = 1)

# Define variables for analysis
columnsToPlot <- list(
  factors = c("HP_Result", "Breast_18m_factor", "Teff_Freq_Factor_Binary",
              "Age_Years", "home_room", "Latrine_in_roome_factor",
              "Delivery_mode_factor", "Weight", "Wasting", "Stunting",
              "family_size", "Home_room_factor", "Sex"),
  numerics = c("WAZ", "HAZ", "BMIZ", "Igapos_bacteria")
)

# Prepare metadata with correct data types
metadataToPlot <- metadata
metadataToPlot$Weight_kg <- as.numeric(metadataToPlot$Weight_kg)
metadataToPlot$Height_cm <- as.numeric(metadataToPlot$Height_cm)
metadataToPlot$WHZ <- as.numeric(metadataToPlot$WHZ)
metadataToPlot$HAZ <- as.numeric(metadataToPlot$HAZ)
metadataToPlot$BMIZ <- as.numeric(metadataToPlot$BMIZ)

# Load ASV count table
countTable <- read_qza(file.path(qiime_output_dir, "table-dada2-filtered.qza"))$data
countTableToPlot <- countTable[, which(colnames(countTable) %in% metadataToPlot$`sample-id`)]
countTableToPlot <- countTableToPlot[, match(metadataToPlot$`sample-id`, colnames(countTableToPlot))]

# Load and prepare taxonomy
taxonomy <- read_qza(file.path(qiime_output_dir, "taxonomy_comparisons_dada2/taxonomy_silva138_normal.qza"))$data
taxonomy2 <- taxonomy %>% dplyr::select(-Confidence)
tPS <- taxonomy2 %>%
  column_to_rownames("Feature.ID") %>%
  separate(Taxon, c("Kingdom", "Phylum", "Class", "Order", "Family", "Genus", "Species"), sep = ";")

# Load alpha diversity metrics
shannonVectors <- read_qza(file.path(qiime_output_dir, "core-metrics-results-dada2/shannon_vector.qza"))$data
evennessVectors <- read_qza(file.path(qiime_output_dir, "core-metrics-results-dada2/evenness_vector.qza"))$data
observedFeaturesVectors <- read_qza(file.path(qiime_output_dir, "core-metrics-results-dada2/observed_features_vector.qza"))$data
faithPDVectors <- read_qza(file.path(qiime_output_dir, "core-metrics-results-dada2/faith_pd_vector.qza"))$data

# Prepare alpha diversity data frame
colnames(faithPDVectors) <- c("index", "faith_pd")
faithPDVectors <- faithPDVectors %>% data.frame %>% column_to_rownames("index")
alphaVectors <- cbind(shannonVectors, evennessVectors, observedFeaturesVectors, faithPDVectors)
alphaVectors <- alphaVectors %>%
  data.frame %>%
  rownames_to_column(colnames(metadataToPlot)[grep("^sample-id", colnames(metadataToPlot), ignore.case = TRUE)]) %>%
  left_join(metadataToPlot)
alphaVectors <- alphaVectors[which(alphaVectors$`sample-id` %in% metadataToPlot$`sample-id`), ]

# Create phyloseq object
ps <- qza_to_phyloseq(
  features = file.path(qiime_output_dir, "table-dada2-filtered.qza"),
  tree = file.path(qiime_output_dir, "rooted-tree-dada2.qza"),
  taxonomy = file.path(qiime_output_dir, "taxonomy_comparisons_dada2/taxonomy_silva138_normal.qza"),
  metadata = file.path(base_dir, "metadata/sample_metadata.txt")
)

# Filter phyloseq object
ps <- subset_samples(ps, Stool_Sample %in% metadataToPlot$Stool_Sample)
phy_tree(ps) <- multi2di(phy_tree(ps))
ps0 <- subset_taxa(ps, !is.na(Phylum) & Phylum != "")

# Calculate prevalence and filter low-prevalence taxa
prevelancedf <- apply(X = otu_table(ps0), MARGIN = 1, FUN = function(x){sum(x > 0)})
prevelancedf <- data.frame(Prevalence = prevelancedf, TotalAbundance = taxa_sums(ps0), tax_table(ps0))
prevelancedf1 <- subset(prevelancedf, Phylum %in% get_taxa_unique(ps0, taxonomic.rank = "Phylum"))

# Visualise prevalence vs abundance
ggplot(prevelancedf1, aes(TotalAbundance, Prevalence / nsamples(ps0), colour = Phylum)) +
  geom_hline(yintercept = 0.01, alpha = 0.5, linetype = 2) +
  geom_point(size = 2, alpha = 0.7) +
  scale_x_log10() +
  xlab("Total Abundance") +
  ylab("Prevalence [Frac. Samples]") +
  facet_wrap(~Phylum) +
  theme(legend.position = "none")

# Apply prevalence threshold (1% of samples)
prevalenceThreshold <- 0.01 * nsamples(ps0)
keepTaxa <- rownames(prevelancedf1)[(prevelancedf1$Prevalence >= prevalenceThreshold)]
ps1 <- prune_taxa(keepTaxa, ps0)
phy_tree(ps1) <- multi2di(phy_tree(ps1))

# Remove Species column from taxonomy table
tax_table(ps0) <- tax_table(ps0)[, -which(colnames(tax_table(ps0)) == "Species")]
tax_table(ps1) <- tax_table(ps1)[, -which(colnames(tax_table(ps1)) == "Species")]

# Save processed data for downstream analysis
save.image(file.path(data_dir, "dataForR.Rdata"))
```

### 2.3 Downstream Analysis

#### 2.3.1 Prepare Data for Visualisation

```{r prepare_viz_data, message=FALSE, warning=FALSE}
# Load processed data
load(file.path(data_dir, "dataForR.Rdata"))

# Calculate CPM and relative abundance
cpms <- edgeR::cpm(countTableToPlot)
ra <- sweep(countTableToPlot, 2, colSums(countTableToPlot), FUN = "/") * 100
log10ra <- log10(ra + 1)

# Filter low-abundance features (CPM > 100 across all samples)
cpms <- cpms[rowSums(cpms) > 100, ]
log2_cpms <- log2(cpms + 10)
scaled_log2_cpms <- scale(log2_cpms, centre = TRUE, scale = TRUE)

# Verify sample order consistency
stopifnot(all(colnames(cpms) == metadataToPlot$`sample-id`))

# Create alpha diversity bins for visualisation
alphaVectors <- alphaVectors[order(alphaVectors$shannon_entropy, decreasing = TRUE), ]
alphaVectors$shannon_bin <- cut_number(x = alphaVectors$shannon_entropy, n = 6, labels = c(1:6))
alphaVectors$shannon_bin <- factor(alphaVectors$shannon_bin, levels = 6:1)
alphaVectors$pielou_bin <- cut_number(x = alphaVectors$pielou_evenness, n = 6, labels = c(1:6))
alphaVectors$pielou_bin <- factor(alphaVectors$pielou_bin, levels = 6:1)
alphaVectors$observed_bin <- cut_number(x = alphaVectors$observed_features, n = 6, labels = c(1:6))
alphaVectors$observed_bin <- factor(alphaVectors$observed_bin, levels = 6:1)
alphaVectors$faith_bin <- cut_number(x = alphaVectors$faith_pd, n = 6, labels = c(1:6))
alphaVectors$faith_bin <- factor(alphaVectors$faith_bin, levels = 6:1)

# Align all data matrices by sample order
metadataToPlot <- metadataToPlot[match(alphaVectors$`sample-id`, metadataToPlot$`sample-id`), ]
cpms <- cpms[, metadataToPlot$`sample-id`]
scaled_log2_cpms <- scaled_log2_cpms[, metadataToPlot$`sample-id`]

# Add alpha diversity to metadata
rownames(alphaVectors) <- alphaVectors[[1]]
stopifnot(all(rownames(alphaVectors) == metadataToPlot$`sample-id`))
stopifnot(all(colnames(cpms) == metadataToPlot$`sample-id`))

metadataToPlot$shannon <- alphaVectors$shannon_entropy
metadataToPlot$shannon_bin <- alphaVectors$shannon_bin
metadataToPlot$pielou <- alphaVectors$pielou_evenness
metadataToPlot$pielou_bin <- alphaVectors$pielou_bin
metadataToPlot$observed <- alphaVectors$observed_features
metadataToPlot$observed_bin <- alphaVectors$observed_bin
metadataToPlot$faith <- alphaVectors$faith_pd
metadataToPlot$faith_bin <- alphaVectors$faith_bin

# Convert variables to factors for plotting
metadataToPlot$family_size <- as.factor(metadataToPlot$family_size)
metadataToPlot$Age_Years <- as.factor(metadataToPlot$Age_Years)
```

#### 2.3.2 Define Colour Palettes

```{r colour_palettes}
# Define custom colour palette
catalystCols <- c(
  "#DC050C", "#FB8072", "#1965B0", "#7BAFDE", "#882E72", "#B17BA6",
  "#FF7F00", "#FDB462", "#E7298A", "#E78AC3", "#33A02C", "#B2DF8A",
  "#55A1B1", "#8DD3C7", "#A6761D", "#E6AB02", "#7570B3", "#BEAED4",
  "#666666", "#999999", "#aa8282", "#d4b7b7", "#8600bf", "#ba5ce3",
  "#808000", "#aeae5c", "#1e90ff", "#00bfff", "#56ff0d", "#cfbf11"
)
cc2 <- catalystCols
cc2 <- colorspace::darken(cc2, 0.4)
catalystCols <- c(catalystCols, cc2)
catalystCols <- paste0(catalystCols, "FF")
colourPalettes <- c("Dark2", "Paired", catalystCols)
```

#### 2.3.3 Define Heatmap Annotations

```{r heatmap_annotations}
# Create top annotation for heatmaps
topAnno <- HeatmapAnnotation(
  "Shannon" = alphaVectors$shannon_entropy,
  "Pielou" = alphaVectors$pielou_evenness,
  "Observed" = alphaVectors$observed_features,
  "Faith PD" = alphaVectors$faith_pd,
  "Age (Years)" = metadataToPlot$Age_Years,
  "Wasting" = metadataToPlot$Wasting_factor,
  "Stunting" = metadataToPlot$Stunting,
  "Weight" = metadataToPlot$Weight,
  "Hp status" = metadataToPlot$HP_Result,
  "Teff" = metadataToPlot$Teff_Freq_Factor_Binary,
  "Breastfed" = metadataToPlot$Breast_18m_factor,
  "Delivery mode" = metadataToPlot$Delivery_mode_factor,
  "Family size" = metadataToPlot$family_size,
  "Rooms in home" = metadataToPlot$Home_room_factor,
  "Latrine in home" = metadataToPlot$Latrine_in_room_factor,
  "IgA" = metadataToPlot$IgApos_bacteria,
  col = list(
    "Shannon" = colorRamp2(breaks = c(0, 4, 8), colors = c("white", "lightblue", "royalblue")),
    "Pielou" = colorRamp2(breaks = c(0, 0.4, 0.8), colors = c("white", "lightpink", "firebrick")),
    "Observed" = colorRamp2(breaks = c(124, 250, 780), colors = c("white", "lightgreen", "forestgreen")),
    "Faith PD" = colorRamp2(breaks = c(10, 30, 70), colors = c("white", "thistle", "orchid4")),
    "IgA" = colorRamp2(breaks = c(0, 50, 100), colors = c("white", "lightpink", "firebrick")),
    "Hp status" = c("POS" = "darkorange", "NEG" = "lightsteelblue3", "EQUIVOCAL" = "grey88"),
    "Teff" = c("Ever" = "goldenrod2", "Never" = "navyblue"),
    "Breastfed" = c("yes" = "pink", "no" = "seagreen4"),
    "Delivery mode" = c("SPO" = "lightsteelblue1", "CS" = "darkorange3"),
    "Wasting" = c("Normal" = "grey88", "MAM" = "firebrick2", "SAM" = "firebrick", "Overweight" = "navyblue"),
    "Stunting" = c("Normal" = "grey88", "Stunting" = "firebrick"),
    "Weight" = c("Normal" = "grey88", "Underweight" = "firebrick"),
    "Family size" = c("2" = "goldenrod1", "3" = "orange1", "4" = "darkorange",
                      "5" = "orangered", "6" = "firebrick2", "7" = "firebrick", "8" = "firebrick4"),
    "Rooms in home" = c("Single" = "plum", "Multiple" = "plum4"),
    "Latrine in home" = c("yes" = "firebrick", "no" = "navyblue"),
    "Age (Years)" = c("2" = "lightblue", "3" = "lightskyblue", "4" = "royalblue3", "5" = "darkblue")
  ),
  annotation_name_gp = gpar(fontsize = 16),
  gp = gpar(col = "white", lwd = 0.1),
  annotation_legend_param = list(
    title_gp = gpar(fontsize = 16, fontface = "bold"),
    labels_gp = gpar(fontsize = 16)
  )
)
```

#### 2.3.4 Prepare Top 40 Genera by Abundance

```{r prepare_top40_genera}
# Align taxonomy to ASV order in count table
asv_order <- rownames(countTableToPlot)
idx <- match(asv_order, rownames(tPS))
keep <- !is.na(idx)
asv_order <- asv_order[keep]
tps_aligned <- tPS[idx[keep], , drop = FALSE]

countTable_aligned <- countTableToPlot[asv_order, , drop = FALSE]
taxonomy_aligned <- tps_aligned[asv_order, , drop = FALSE]

countTable_withTax <- cbind(
  taxonomy_aligned,
  countTableToPlot[asv_order, , drop = FALSE]
)

# Identify taxonomy vs count columns
taxonomy_cols <- colnames(taxonomy_aligned)
sample_cols <- setdiff(colnames(countTable_withTax), taxonomy_cols)

# Extract counts matrix
counts_asv <- as.matrix(countTable_withTax[, sample_cols, drop = FALSE])

# Build Genus grouping vector
genus_vec <- gsub("^g__", "", countTable_withTax$Genus)
genus_vec[is.na(genus_vec) | genus_vec == ""] <- "Unclassified_Genus"

# Aggregate counts by Genus
counts_genus <- rowsum(counts_asv, group = genus_vec, reorder = TRUE)

# Create genus-level taxonomy map
phylum_vec <- gsub("^p__", "", countTable_withTax$Phylum)
family_vec <- gsub("^f__", "", countTable_withTax$Family)
phylum_vec[is.na(phylum_vec) | phylum_vec == ""] <- "Unclassified_Phylum"
family_vec[is.na(family_vec) | family_vec == ""] <- "Unclassified_Family"

# Function to get majority taxonomy assignment
majority <- function(x) names(sort(table(x), decreasing = TRUE))[1]
tax_genus <- aggregate(
  data.frame(Phylum = phylum_vec, Family = family_vec),
  by = list(Genus = genus_vec),
  FUN = majority
)
rownames(tax_genus) <- tax_genus$Genus
tax_genus <- tax_genus[rownames(counts_genus), , drop = FALSE]

# Select top 40 genera by total abundance
genus_totals <- rowSums(counts_genus)
top40_genus <- head(sort(genus_totals, decreasing = TRUE), n = 40)

counts_top40 <- counts_genus[names(top40_genus), , drop = FALSE]
tax_top40 <- tax_genus[names(top40_genus), , drop = FALSE]

# Calculate relative abundances and log-transform
ra_top40 <- sweep(counts_top40, 2, pmax(colSums(counts_top40), 1), "/")
ra_top40 <- ra_top40 * 100  # Convert to percentage
log10ra_top40 <- log10(ra_top40 + 1e-2)
```

#### 2.3.5 Generate Heatmap of Top 40 Genera

```{r heatmap_top40, fig.height=17, fig.width=22}
# Set genus order (high to low abundance)
genus_order <- names(top40_genus)

# Define colour palettes for phylum
phylum_levels <- unique(tax_top40$Phylum %>% gsub("^p__", "", .))
top40_colours_phylum <- {
  n <- length(phylum_levels)
  pal <- RColorBrewer::brewer.pal(max(3, n), colourPalettes[[1]])[seq_len(n)]
  names(pal) <- phylum_levels
  pal
}

# Define colour palettes for family
family_vals <- tax_top40$Family[match(genus_order, rownames(tax_top40))] %>% gsub("^f__", "", .)
family_vals[is.na(family_vals) | family_vals == ""] <- "Unclassified_Family"
family_levels <- unique(family_vals)
top40_colours_family <- {
  n <- length(family_levels)
  pal <- catalystCols[seq_len(n)]
  names(pal) <- family_levels
  pal
}

# Create left annotation (taxonomy)
leftAnno <- rowAnnotation(
  "Phylum" = (tax_top40$Phylum[match(genus_order, rownames(tax_top40))] %>% gsub("^p__", "", .)),
  "Family" = family_vals,
  col = list(
    "Phylum" = top40_colours_phylum,
    "Family" = top40_colours_family
  ),
  annotation_name_gp = gpar(fontsize = 16),
  annotation_legend_param = list(
    labels_gp = gpar(fontsize = 16),
    title_gp = gpar(fontsize = 16, fontface = "bold")
  ),
  gp = gpar(col = "white", lwd = 0.1, fontsize = 16)
)

# Create right annotation (genus names)
rightAnno <- rowAnnotation(
  "Genus" = anno_text(
    x = genus_order,
    gp = gpar(fontsize = 16, fontface = "italic"),
    just = "left"
  )
)

# Generate and save heatmap
pdf(file.path(results_dir, "heatmap_top40_genera_by_shannon.pdf"), width = 26, height = 17)
h1 <- Heatmap(
  matrix = as.matrix(log10ra_top40[genus_order, , drop = FALSE]),
  show_row_names = FALSE,
  show_column_names = FALSE,
  name = "RA log10 (%)",
  left_annotation = leftAnno,
  right_annotation = rightAnno,
  top_annotation = topAnno,
  cluster_columns = FALSE,
  column_split = alphaVectors$shannon_bin,
  col = mako(100),
  heatmap_legend_param = list(
    labels_gp = gpar(fontsize = 16),
    title_gp = gpar(fontsize = 16, fontface = "bold")
  )
) %>% draw(
  merge_legend = FALSE,
  heatmap_legend_side = "left",
  annotation_legend_side = "bottom"
)
dev.off()
h1
```

### 2.4 Cramer's V Analysis of Categorical Variables

```{r cramers_v_analysis}
# Load metadata for Cramer's V analysis
metadata_cramers <- read.csv(file.path(base_dir, "metadata/sample_metadata.txt"),
                              sep = "\t", row.names = 1, check.names = FALSE)

# Select candidate categorical variables
candidate_cats <- c(
  "HP_Result", "Teff_Freq_Factor_Binary", "Breast_18m_factor", "Delivery_mode_factor",
  "Wasting_factor", "Stunting", "Weight",
  "family_size", "Latrine_in_room_factor", "Home_room_factor",
  "Age_Years"
)
cat_vars <- intersect(candidate_cats, colnames(metadata_cramers))
stopifnot(length(cat_vars) > 0)

df <- metadata_cramers[, cat_vars, drop = FALSE]

# Coerce to factors and filter ultra-rare levels
min_count <- 3
df[] <- lapply(df, function(x) {
  f <- factor(x)
  tab <- table(f)
  keep <- names(tab[tab >= min_count])
  f[!(f %in% keep)] <- NA
  droplevels(f)
})

# Compute Cramer's V matrix
vars <- colnames(df)
n <- length(vars)
cv_mat <- matrix(NA_real_, n, n, dimnames = list(vars, vars))

for (i in seq_len(n)) {
  for (j in i:n) {
    v1 <- df[[i]]
    v2 <- df[[j]]
    ok <- complete.cases(v1, v2)

    if (sum(ok) > 0) {
      tab <- table(v1[ok], v2[ok])
      if (nrow(tab) > 1 && ncol(tab) > 1) {
        cv <- suppressWarnings(rstatix::cramer_v(tab, bias.correct = TRUE))
        cv_mat[i, j] <- cv_mat[j, i] <- cv
      }
    }
  }
}
diag(cv_mat) <- 1

# Generate heatmap of Cramer's V values
cv_long <- na.omit(reshape2::melt(cv_mat, varnames = c("Var1", "Var2"), value.name = "cv"))

heatmap_corr <- ggplot(cv_long, aes(Var1, Var2, fill = cv)) +
  geom_tile() +
  scale_fill_gradient(
    limits = c(0, 1),
    low = "#005AB5",
    high = "#DC3220",
    na.value = "grey90",
    name = "Cramer's V"
  ) +
  coord_equal() +
  theme_minimal(base_size = 14) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1, size = 12, face = "bold"),
    axis.text.y = element_text(size = 12, face = "bold"),
    axis.title = element_blank(),
    legend.title = element_text(size = 12),
    legend.text = element_text(size = 10),
    plot.title = element_text(size = 12, face = "bold", hjust = 0.5)
  ) +
  labs(title = "Heatmap of Cramer's V associations amongst categorical confounders")

print(heatmap_corr)

ggsave(
  filename = file.path(results_dir, "heatmap_cramers_v.pdf"),
  plot = heatmap_corr,
  width = 6, height = 5, units = "in"
)

# Identify strongly associated pairs
threshold <- 0.50
upper <- subset(cv_long, as.character(Var1) < as.character(Var2))
strong_pairs <- subset(upper, cv >= threshold)
strong_pairs <- strong_pairs[order(-strong_pairs$cv), , drop = FALSE]

cat("\nStrongly associated pairs (Cramer's V ≥", threshold, "):\n")
print(strong_pairs)

# Suggest non-redundant variable set
if (nrow(strong_pairs) > 0) {
  g <- igraph::graph_from_data_frame(
    strong_pairs[, c("Var1", "Var2")],
    directed = FALSE,
    vertices = vars
  )
  memb <- igraph::components(g)$membership

  rep_by_comp <- tapply(names(memb), memb, function(nodes) {
    nodes[which.max(sapply(nodes, function(v) sum(!is.na(df[[v]]))))]
  })

  suggested_keep <- sort(unique(c(rep_by_comp, setdiff(vars, names(memb)))))
} else {
  suggested_keep <- vars
}

cat("\nSuggested non-redundant set:\n")
print(suggested_keep)
```

### 2.5 MaAsLin3 Differential Abundance Analysis

#### 2.5.1 Prepare Phyloseq and Genus-Level Data

```{r prepare_maaslin_data}
# Load raw taxonomy and split into ranks
tax_raw <- read_qza(file.path(qiime_output_dir, "taxonomy_comparisons_dada2/taxonomy_silva138_normal.qza"))$data
tax_split <- tax_raw %>%
  separate(Taxon, into = c("Kingdom", "Phylum", "Class", "Order", "Family", "Genus", "Species"),
           sep = ";", fill = "right", remove = FALSE) %>%
  mutate(across(c(Kingdom, Phylum, Class, Order, Family, Genus, Species), ~trimws(.)))

# Build OTU table
asv <- read_qza(file.path(qiime_output_dir, "table-dada2-filtered.qza"))$data
otu_mat <- as.matrix(asv)
otu <- otu_table(otu_mat, taxa_are_rows = TRUE)

# Match taxonomy to OTU taxa order
tx <- tax_split[match(taxa_names(otu), tax_split$Feature.ID),
                c("Kingdom", "Phylum", "Class", "Order", "Family", "Genus", "Species")]
rownames(tx) <- taxa_names(otu)
tx <- tax_table(as.matrix(tx))

# Align metadata to OTU samples
meta <- metadata
rownames(meta) <- meta$`sample-id`
keep_samp <- intersect(colnames(otu_mat), rownames(meta))
otu <- otu_table(otu_mat[, keep_samp, drop = FALSE], taxa_are_rows = TRUE)
meta <- meta[keep_samp, , drop = FALSE]

# Verify alignment
stopifnot(identical(taxa_names(otu), rownames(tx)))
stopifnot(identical(sample_names(otu), rownames(meta)))

# Build phyloseq object
phy <- phyloseq(otu, tx, sample_data(meta))

# Collapse to Genus level
phy_genus <- tax_glom(phy, taxrank = "Genus", NArm = TRUE)
genus_counts <- as(otu_table(phy_genus), "matrix")
colnames(genus_counts) <- gsub("-", "_", colnames(genus_counts))

# Assign genus names and merge duplicates
gen_labels <- as.character(tax_table(phy_genus)[, "Genus"])
gen_labels[is.na(gen_labels) | gen_labels == ""] <- "Unclassified_Genus"
genus_counts <- rowsum(genus_counts, group = gen_labels, reorder = TRUE)

# Load MaAsLin metadata - UPDATE THIS PATH FOR YOUR SYSTEM
metadataToMaaslin <- read.csv(
  file.path(base_dir, "metadata/metadata_maaslin3.csv"),
  row.names = 1, check.names = FALSE
)

# Align count table to metadata
genus_counts <- genus_counts[, rownames(metadataToMaaslin)]
```

#### 2.5.2 H. pylori Status Analysis

```{r maaslin_hp}
# Filter for H. pylori positive and negative samples
metadataToMaaslin_HP <- metadataToMaaslin[which(metadataToMaaslin$HP_Result %in% c("POS", "NEG")), ]
genus_counts_HP <- genus_counts[, rownames(metadataToMaaslin_HP)]

# Verify sample alignment
stopifnot(all(colnames(genus_counts_HP) == rownames(metadataToMaaslin_HP)))

# Centre age for better model interpretation
metadataToMaaslin_HP$Age_c <- scale(metadataToMaaslin_HP$Age_Years, center = TRUE, scale = FALSE)

# Run MaAsLin3 analysis
set.seed(1)
fit_out_hp <- maaslin3(
  input_data = genus_counts_HP,
  input_metadata = metadataToMaaslin_HP,
  output = file.path(results_dir, "Maaslin3/HP_analysis"),
  formula = ~ HP_Result + Age_c,
  cores = 1,
  summary_plot_first_n = 40
)
```

#### 2.5.3 Stunting Analysis

```{r maaslin_stunting}
# Filter for stunting analysis
metadataToMaaslin_Stunting <- metadataToMaaslin[which(metadataToMaaslin$Stunting %in% c("Stunting", "Normal")), ]
genus_counts_Stunting <- genus_counts[, rownames(metadataToMaaslin_Stunting)]

# Verify sample alignment
stopifnot(all(colnames(genus_counts_Stunting) == rownames(metadataToMaaslin_Stunting)))

# Centre age
metadataToMaaslin_Stunting$Age_c <- scale(metadataToMaaslin_Stunting$Age_Years, center = TRUE, scale = FALSE)

# Run MaAsLin3 analysis
set.seed(1)
fit_out_stunting <- maaslin3(
  input_data = genus_counts_Stunting,
  input_metadata = metadataToMaaslin_Stunting,
  output = file.path(results_dir, "Maaslin3/Stunting_analysis"),
  formula = ~ Stunting + Age_c,
  cores = 1,
  summary_plot_first_n = 40
)
```

#### 2.5.4 Teff Consumption Analysis

```{r maaslin_teff}
# Filter for teff consumption analysis
metadataToMaaslin_Teff <- metadataToMaaslin[which(metadataToMaaslin$Teff_Freq_Factor_Binary %in% c("Ever", "Never")), ]
genus_counts_Teff <- genus_counts[, rownames(metadataToMaaslin_Teff)]

# Verify sample alignment
stopifnot(all(colnames(genus_counts_Teff) == rownames(metadataToMaaslin_Teff)))

# Centre age
metadataToMaaslin_Teff$Age_c <- scale(metadataToMaaslin_Teff$Age_Years, center = TRUE, scale = FALSE)

# Run MaAsLin3 analysis
set.seed(1)
fit_out_teff <- maaslin3(
  input_data = genus_counts_Teff,
  input_metadata = metadataToMaaslin_Teff,
  output = file.path(results_dir, "Maaslin3/Teff_analysis"),
  formula = ~ Teff_Freq_Factor_Binary + Age_c,
  cores = 1,
  summary_plot_first_n = 40
)
```

#### 2.5.5 Home Room Analysis

```{r maaslin_homeroom}
# Filter for home room analysis
metadataToMaaslin_Homeroom <- metadataToMaaslin[which(metadataToMaaslin$Home_room_factor %in% c("Single", "Multiple")), ]
genus_counts_Homeroom <- genus_counts[, rownames(metadataToMaaslin_Homeroom)]

# Verify sample alignment
stopifnot(all(colnames(genus_counts_Homeroom) == rownames(metadataToMaaslin_Homeroom)))

# Centre age
metadataToMaaslin_Homeroom$Age_c <- scale(metadataToMaaslin_Homeroom$Age_Years, center = TRUE, scale = FALSE)

# Run MaAsLin3 analysis
set.seed(1)
fit_out_homeroom <- maaslin3(
  input_data = genus_counts_Homeroom,
  input_metadata = metadataToMaaslin_Homeroom,
  output = file.path(results_dir, "Maaslin3/Homeroom_analysis"),
  formula = ~ Home_room_factor + Age_c,
  cores = 1,
  summary_plot_first_n = 40
)
```

#### 2.5.6 Visualise MaAsLin3 Results

```{r plot_maaslin_results}
library(patchwork)

# Define analysis configurations
analyses <- list(
  "HP (POS vs NEG)" = list(
    dir = file.path(results_dir, "Maaslin3/HP_analysis"),
    var = "HP_Result",
    value = "POS"
  ),
  "Stunting (Stunting vs Normal)" = list(
    dir = file.path(results_dir, "Maaslin3/Stunting_analysis"),
    var = "Stunting",
    value = "Stunting"
  ),
  "Teff (Never vs Ever)" = list(
    dir = file.path(results_dir, "Maaslin3/Teff_analysis"),
    var = "Teff_Freq_Factor_Binary",
    value = "Never"
  ),
  "Home room (Single vs Multiple)" = list(
    dir = file.path(results_dir, "Maaslin3/Homeroom_analysis"),
    var = "Home_room_factor",
    value = "Single"
  )
)

# Helper function to read and select top/bottom features
read_and_select_tb10 <- function(dir_path, var, value_keep, label, n_each = 10) {
  f_all <- file.path(dir_path, "all_results.tsv")
  stopifnot(file.exists(f_all))
  df <- read_tsv(f_all, show_col_types = FALSE)

  # Harmonise column names across MaAsLin versions
  if (!"coef" %in% names(df) && "beta" %in% names(df)) df <- dplyr::rename(df, coef = beta)
  if (!"stderr" %in% names(df) && "se" %in% names(df)) df <- dplyr::rename(df, stderr = se)
  if (!"value" %in% names(df) && "level" %in% names(df)) df <- dplyr::rename(df, value = level)
  if (!"qval_individual" %in% names(df) && "qval" %in% names(df)) df <- dplyr::rename(df, qval_individual = qval)

  # Keep relevant columns
  keep_cols <- intersect(c("feature", "metadata", "value", "coef", "stderr", "qval_individual", "model", "error"), names(df))
  df <- df[, keep_cols, drop = FALSE]

  # Filter for target variable and remove error rows
  df <- df %>%
    filter(model == "abundance",
           metadata == var,
           value == value_keep) %>%
    filter(is.na(error))

  if (nrow(df) == 0) {
    warning("No rows after filtering for ", label)
    return(NULL)
  }

  # Prepare for plotting
  df <- df %>%
    mutate(
      lower = coef - ifelse(is.na(stderr), 0, stderr),
      upper = coef + ifelse(is.na(stderr), 0, stderr),
      feature_label = str_wrap(feature, width = 40),
      Analysis = label
    )

  # Select top positive and bottom negative
  top_pos <- df %>% filter(coef > 0) %>% arrange(desc(coef)) %>% slice_head(n = n_each)
  bottom_neg <- df %>% filter(coef < 0) %>% arrange(coef) %>% slice_head(n = n_each)

  # Create visual separator
  separator <- data.frame(
    feature = NA, metadata = NA, value = NA,
    coef = NA_real_, stderr = NA_real_, qval_individual = NA_real_,
    model = NA, error = NA_character_, lower = NA_real_, upper = NA_real_,
    feature_label = "         ", Analysis = label,
    stringsAsFactors = FALSE
  )

  # Combine and order
  out <- dplyr::bind_rows(top_pos, separator, bottom_neg) %>%
    mutate(feature_label = factor(feature_label, levels = rev(unique(feature_label))))

  return(out)
}

# Generate plots for each analysis
plot_list <- list()
table_list <- list()

for (lab in names(analyses)) {
  info <- analyses[[lab]]
  df_plot <- read_and_select_tb10(info$dir, info$var, info$value, lab, n_each = 10)
  if (is.null(df_plot)) next

  # Store table
  table_list[[lab]] <- df_plot %>%
    filter(!is.na(coef)) %>%
    select(Analysis, feature, feature_label, metadata, value, coef, stderr, lower, upper, qval_individual)

  # Create plot
  p <- ggplot(df_plot, aes(x = coef, y = feature_label)) +
    geom_errorbarh(aes(xmin = lower, xmax = upper), height = 0.2, colour = "grey50", na.rm = TRUE) +
    geom_point(
      aes(fill = qval_individual),
      size = 4, shape = 21, stroke = 0.6, colour = "black", na.rm = TRUE
    ) +
    scale_fill_gradientn(
      colours = c("purple4", "plum2"),
      values = scales::rescale(c(0.3, 1.0)),
      limits = c(0.3, 1.0),
      oob = scales::squish,
      name = expression("Abundance  " * P[FDR]),
      trans = "log10",
      guide = guide_colorbar(barwidth = 1, barheight = 10)
    ) +
    geom_vline(xintercept = 0, linetype = "dashed", colour = "grey40") +
    labs(
      title = lab,
      x = "Effect size (β-coefficient)",
      y = NULL
    ) +
    theme_bw(base_size = 12) +
    theme(
      axis.text.y = element_text(size = 10),
      axis.title.x = element_text(size = 12, face = "bold"),
      plot.title = element_text(face = "bold"),
      panel.grid.major.y = element_line(colour = "grey85", linewidth = 0.3),
      legend.title = element_text(size = 11, face = "bold")
    )

  if ("ggprism" %in% .packages()) {
    p <- p + ggprism::theme_prism(base_size = 12, border = TRUE)
  }

  plot_list[[lab]] <- p
}

# Combine all panels
combined <- wrap_plots(plotlist = plot_list, ncol = 1)
print(combined)

# Save individual plots
for (lab in names(plot_list)) {
  p <- plot_list[[lab]]
  fname <- paste0("MaAsLin3_TopBottom10_", gsub("[^A-Za-z0-9]+", "_", lab), ".pdf")
  ggsave(
    filename = file.path(results_dir, fname),
    plot = p,
    width = 7, height = 6, units = "in"
  )
  message("Saved: ", fname)
}
```

---

## Session Information

```{text}
R version 4.5.0 (2025-04-11)
Platform: x86_64-pc-linux-gnu
Running under: Debian GNU/Linux 12 (bookworm)

Matrix products: default
BLAS:   /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.11.0
LAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.11.0  LAPACK version 3.11.0

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

time zone: Europe/Zurich
tzcode source: system (glibc)

attached base packages:
 [1] stats4    grid      parallel  stats     graphics  grDevices utils
 [8] datasets  methods   base

other attached packages:
 [1] igraph_2.2.0                reshape2_1.4.4
 [3] readxl_1.4.5                RColorBrewer_1.1-3
 [5] viridis_0.6.5               viridisLite_0.4.2
 [7] circlize_0.4.16             ggbeeswarm_0.7.2
 [9] DT_0.33                     ggrepel_0.9.6
[11] DESeq2_1.48.1               SummarizedExperiment_1.38.1
[13] Biobase_2.68.0              MatrixGenerics_1.20.0
[15] GenomicRanges_1.60.0        GenomeInfoDb_1.44.3
[17] IRanges_2.42.0              S4Vectors_0.49.0
[19] BiocGenerics_0.54.1         generics_0.1.4
[21] ComplexHeatmap_2.24.0       matrixStats_1.5.0
[23] kableExtra_1.4.0            rstatix_0.7.2
[25] ggpubr_0.6.0                ape_5.8-1
[27] phyloseq_1.52.0             vegan_2.6-10
[29] lattice_0.22-7              permute_0.9-7
[31] ggprism_1.0.7               lubridate_1.9.4
[33] forcats_1.0.1               stringr_1.5.2
[35] dplyr_1.1.4                 purrr_1.1.0
[37] readr_2.1.5                 tidyr_1.3.1
[39] tibble_3.3.0                ggplot2_4.0.0
[41] tidyverse_2.0.0             qiime2R_0.99.6

loaded via a namespace (and not attached):
 [1] rstudioapi_0.17.1       jsonlite_2.0.0          shape_1.4.6.1
 [4] magrittr_2.0.4          NADA_1.6-1.1            farver_2.1.2
 [7] rmarkdown_2.29          GlobalOptions_0.1.2     vctrs_0.6.5
[10] multtest_2.64.0         base64enc_0.1-3         htmltools_0.5.8.1
[13] S4Arrays_1.8.1          truncnorm_1.0-9         broom_1.0.8
[16] cellranger_1.1.0        Rhdf5lib_1.29.2         SparseArray_1.8.1
[19] Formula_1.2-5           rhdf5_2.51.2            htmlwidgets_1.6.4
[22] plyr_1.8.9              lifecycle_1.0.4         iterators_1.0.14
[25] pkgconfig_2.0.3         Matrix_1.7-3            R6_2.6.1
[28] fastmap_1.2.0           GenomeInfoDbData_1.2.14 clue_0.3-66
[31] digest_0.6.37           colorspace_2.1-1        textshaping_1.0.1
[34] Hmisc_5.2-3             timechange_0.3.0        httr_1.4.7
[37] abind_1.4-8             mgcv_1.9-3              compiler_4.5.0
[40] withr_3.0.2             doParallel_1.0.17       htmlTable_2.4.3
[43] S7_0.2.0                backports_1.5.0         BiocParallel_1.42.2
[46] carData_3.0-5           ggsignif_0.6.4          MASS_7.3-65
[49] DelayedArray_0.34.1     rjson_0.2.23            biomformat_1.36.0
[52] tools_4.5.0             vipor_0.4.7             foreign_0.8-90
[55] beeswarm_0.4.0          nnet_7.3-20             glue_1.8.0
[58] nlme_3.1-168            rhdf5filters_1.19.2     checkmate_2.3.2
[61] cluster_2.1.8.1         ade4_1.7-23             gtable_0.3.6
[64] tzdb_0.5.0              data.table_1.17.8       hms_1.1.3
[67] xml2_1.3.8              car_3.1-3               XVector_0.48.0
[70] foreach_1.5.2           pillar_1.11.1           splines_4.5.0
[73] survival_3.8-3          tidyselect_1.2.1        locfit_1.5-9.12
[76] Biostrings_2.76.0       knitr_1.50              gridExtra_2.3
[79] svglite_2.2.1           zCompositions_1.5.0-4   xfun_0.52
[82] stringi_1.8.7           UCSC.utils_1.4.0        yaml_2.3.10
[85] evaluate_1.0.3          codetools_0.2-20        cli_3.6.5
[88] rpart_4.1.24            systemfonts_1.2.3       dichromat_2.0-0.1
[91] Rcpp_1.1.0              png_0.1-8               scales_1.4.0
[94] crayon_1.5.3            GetoptLong_1.0.5        rlang_1.1.6
```